services:
  api:
    build: ./docker/Dockerfile.api
    ports: ["8000:8000"]
    deploy:
      resources:
        limits:
          memory: 2G # API stays lean

  worker_math:
    build: ./docker/Dockerfile.worker
    command: celery -A src.workers.tasks worker --loglevel=info -Q math_queue
    deploy:
      resources:
        limits:
          memory: 4G # TSFRESH needs room to breathe

  worker_llm:
    build: ./docker/Dockerfile.worker
    command: celery -A src.workers.tasks worker --loglevel=info -Q llm_queue
    volumes: ["./models:/app/models"]
    deploy:
      resources:
        limits:
          memory: 6G # SLM gets its own dedicated RAM slice